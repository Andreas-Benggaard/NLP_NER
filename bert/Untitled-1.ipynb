{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-MISCpart', 'I-PERpart', 'B-MISCpart', 'B-ORGderiv', 'I-LOC', 'B-LOCderiv', 'I-MISC', 'B-ORGpart', 'O', 'B-PER', 'I-PER', 'I-LOCpart', 'I-ORG', 'B-PERpart', 'B-LOCpart', 'I-LOCderiv', 'I-ORGpart', 'B-MISC', 'B-ORG', 'I-ORGderiv', 'B-MISCderiv', 'B-PERderiv', 'B-LOC'}\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "\n",
    "def read_conll_file(file_name):\n",
    "    \"\"\"\n",
    "    read in conll file\n",
    "    \n",
    "    :param file_name: path to read from\n",
    "    :yields: list of words and labels for each sentence\n",
    "    \"\"\"\n",
    "    current_words = []\n",
    "    current_tags = []\n",
    "\n",
    "    for line in codecs.open(file_name, encoding='utf-8'):\n",
    "        line = line.strip()\n",
    "\n",
    "        if line:\n",
    "            if line[0] == '#':\n",
    "                continue # skip comments\n",
    "            tok = line.split('\\t')\n",
    "            word = tok[0]\n",
    "            tag = tok[1]\n",
    "\n",
    "            current_words.append(word)\n",
    "            current_tags.append(tag)\n",
    "        else:\n",
    "            if current_words:  # skip empty lines\n",
    "                yield((current_words, current_tags))\n",
    "            current_words = []\n",
    "            current_tags = []\n",
    "\n",
    "    # check for last one\n",
    "    if current_tags != [] and not raw:\n",
    "        yield((current_words, current_tags))\n",
    "\n",
    "label_set = set()\n",
    "for words, labels in read_conll_file('en_ewt_nn_train.conll'):\n",
    "    for label in labels:\n",
    "        label_set.add(label)\n",
    "print(label_set)\n",
    "\n",
    "SMOOTH = 0.1\n",
    "UNK = '<UNK>'\n",
    "BEG = '<S>'\n",
    "END = '</S>'\n",
    "\n",
    "\n",
    "# emission probs:\n",
    "emissions = {} # final result, give label then word to find emission prob of word\n",
    "totals = {} # total count for each label needed for C(ti) in formula\n",
    "\n",
    "for label in label_set:\n",
    "    # 1 for smoothing!\n",
    "    emissions[label] = {UNK:SMOOTH}\n",
    "    totals[label] = SMOOTH\n",
    "    \n",
    "for words, labels in read_conll_file('en_ewt_nn_train.conll'):\n",
    "    for word, label in zip(words, labels):\n",
    "        totals[label] += 1 #Originally SMOOTH but not sure why\n",
    "        if word not in emissions[label]:\n",
    "            emissions[label][word] = 1 + SMOOTH # 2 because of smoothing!\n",
    "        else:\n",
    "            emissions[label][word] += 1\n",
    "\n",
    "# got the counts, now turn them into probs\n",
    "for label in emissions:\n",
    "    for word in emissions[label]:\n",
    "        emissions[label][word] /= totals[label]\n",
    "\n",
    "# to deal with UNK\n",
    "def emissionProb(label,word):\n",
    "    if word in emissions[label].keys():\n",
    "        return emissions[label][word]\n",
    "    else:\n",
    "        return emissions[label][UNK]\n",
    "\n",
    "# transmission prob:\n",
    "\n",
    "tagCounts = {} #Counts of next tags for each tag\n",
    "\n",
    "label_set_ext = label_set.copy() #label_set defined in first code cell\n",
    "label_set_ext.add(BEG) \n",
    "label_set_ext.add(END)\n",
    "\n",
    "# Smoothing\n",
    "for label in label_set_ext:\n",
    "    tagCounts[label] = {}\n",
    "    for label2 in label_set_ext:\n",
    "        tagCounts[label].setdefault(label2,SMOOTH)\n",
    "\n",
    "for _, labels in read_conll_file('en_ewt_nn_train.conll'):\n",
    "    for labelIdx in range(len(labels)):\n",
    "        \n",
    "        curLabel = labels[labelIdx]\n",
    "        if labelIdx == 0: # Start of sentence is handled differently\n",
    "            prev = BEG\n",
    "        else:\n",
    "            prev = labels[labelIdx-1]\n",
    "        \n",
    "        tagCounts[prev][curLabel] += 1\n",
    "        \n",
    "    # add prob. to </S> i.e end of sentence is handled differently\n",
    "    tagCounts[curLabel][END] += 1\n",
    "\n",
    "# Summing counts for each tag to get tag priors\n",
    "tagCountSums = {tag:sum(tagCounts[tag].values()) for tag in tagCounts.keys()}\n",
    "\n",
    "for tag1 in tagCounts:\n",
    "    for tag2 in tagCounts[tag1]:\n",
    "        tagCounts[tag1][tag2] /= tagCountSums[tag1]\n",
    "        \n",
    "transition = tagCounts\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "def viterbi(sentence):\n",
    "    row_count = len(label_set)\n",
    "    labels = list(label_set)\n",
    "\n",
    "    # scores is of shape(labels,words)\n",
    "    scores = np.array([[0.0]*len(sentence) for i in range(row_count)])\n",
    "    came_from = np.array([[0]*len(sentence) for i in range(row_count)])\n",
    "    \n",
    "    for idx, word in enumerate(sentence):\n",
    "        for jdx, tag in enumerate(labels):\n",
    "            if tag in [BEG,END]:\n",
    "                continue\n",
    "            \n",
    "            if idx == 0:\n",
    "                for x in range(len(labels)):\n",
    "                    scores[jdx,idx] = emissionProb(tag,word)*transition[BEG][tag]\n",
    "            \n",
    "            else:\n",
    "                cand_scores = [0]*len(labels)\n",
    "                for kdx, candlabel in enumerate(labels):\n",
    "                    #print(tag,candlabel)\n",
    "                    cand_scores[kdx] = emissionProb(tag,word)*transition[candlabel][tag]*scores[kdx,idx-1]\n",
    "                scores[jdx,idx] = max(cand_scores)\n",
    "                came_from[jdx,idx] = np.argmax(cand_scores)\n",
    "            \n",
    "    path = [np.argmax(scores[:,-1])]\n",
    "    for i in range(len(sentence)-1,0,-1):\n",
    "        node = path[-1]\n",
    "        path.append(int(came_from[int(node),i]))\n",
    "    path.reverse()\n",
    "    res_labels = []\n",
    "    for i in path:\n",
    "        res_labels.append(labels[i])\n",
    "    return res_labels\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.035439714982186385\n",
      "O-I-ORGderiv 3427\n",
      "O-I-MISCpart 1254\n",
      "B-LOC-I-ORGderiv 80\n",
      "O-B-MISCpart 60\n",
      "B-ORG-I-ORGderiv 52\n",
      "I-ORG-I-ORGderiv 41\n",
      "I-MISC-I-ORGderiv 28\n",
      "B-MISC-I-ORGderiv 27\n",
      "B-LOCderiv-I-ORGderiv 26\n",
      "B-PER-I-ORGderiv 20\n"
     ]
    }
   ],
   "source": [
    "#analysis and accuracy\n",
    "total = 0\n",
    "correct = 0\n",
    "confusions= {}\n",
    "data = list(read_conll_file('en_ewt_nn_answers_test.conll'))\n",
    "for words, labels in data:\n",
    "    res_labels = viterbi(words)\n",
    "    for x,y in zip(labels, res_labels):\n",
    "        total += 1\n",
    "        if x == y:\n",
    "            correct += 1\n",
    "        else:\n",
    "            confusion = x + '-' + y\n",
    "            if confusion in confusions:\n",
    "                confusions[confusion] += 1\n",
    "            else:\n",
    "                confusions[confusion] = 1\n",
    "print(correct/total)  \n",
    "for k in sorted(confusions, key=confusions.get, reverse=True)[:10]:\n",
    "    print(k, confusions[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'O', 'B-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart', 'I-MISCpart']\n"
     ]
    }
   ],
   "source": [
    "print(res_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "267163d9178a8f2c7228cfd8c24fe2c65a021fcd5286aa000017a8cb82985976"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
